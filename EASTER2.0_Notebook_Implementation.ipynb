{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1LR0G4WFmZopy9RlfDwtYqAocK0JsoqTD",
      "authorship_tag": "ABX9TyNeL0flIX2WwnL6q3zj+CmL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanikak96/Data-Science-Projects/blob/master/EASTER2.0_Notebook_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handwriting Text Recognition: EASTER 2.0\n",
        "\n",
        "Handwriting Recognition also termed as HTR(Handwritten Text Recognition) is a machine learning method that aims at giving the machines an ability to read human handwriting from real-world documents(images). \n",
        "\n",
        "### Challenges in HTR \n",
        "- They require a huge amount of labeled training data.\n",
        "- Due to a large number of training parameters, they are hard to train and slow in inference.\n",
        "- As they are slow, they require huge deployment cost(hardware requirements) to make them useful in real-time applications.\n",
        "-  Models are complex in nature and difficult to scale(stacked LSTMs, complex attention layers).\n",
        "\n",
        "EASTER stands for Efficient and Scalable Text Recognizer. It is a fully convolutional architecture that utilizes only 1-D Convolutional layers in the encoder and adds a CTC-decoder(Connectionist Temporal Classification) at the end.\n",
        "\n",
        "### How do you apply the one dimensional convolutions on a two-dimensional image?\n",
        "-  Consider an input image of size 600 X 50 (W X H). Here, if you draw any vertical line in this image, you will only cut a single character (if not drawn in white-space), and if you draw a horizontal line you will probably end up cutting all the characters.\n",
        "- Along the height of the image you will only find the properties of a single character while along the width you will find all different characters as you move from left-to-right.\n",
        "- A one-dimensional filter of kernel size-3 actually means a filter of dimension 3 in the time dimension(along the width, 3 pixels at a time) that covers the overall height of 50 pixels(H). So, basically a filter of kernel size-3 means a filter of 3×50 (or 3xH) dimensions\n",
        "- Each scan stores the information of the observed character(or part of the character).\n",
        "- This information is finally passed to a softmax layer that gives a probability distribution over all the characters possible for each time-step along the width. This probability distribution is then passed to the CTC decoding layer to generate the final output sequence.\n",
        "\n",
        "### EASTER 2.0\n",
        "- Easter2.0 is built by stacking 14 layers of standard 1D convolutional layers, batch normalization layers, ReLU, and Dropout. \n",
        "- With the target of balancing the number of channels, a residual connection is first projected through a 1 x 1 convolution layer, followed by a batch normalization layer. The result of this batch normalization layer is combined with the SE layer’s output in the final convolution block, which comes before the ReLU and Dropout layers. \n",
        "- Finally, a softmax layer is used to predict the distribution of probabilities over the characters of a given vocabulary. \n",
        "- Using the SE module, Easter2.0 can access global context similarly to RNN/Transformers and has CNN’s speed and parameter efficiency. \n",
        "\n",
        "- In addition to the new suggested architecture, the authors introduced a novel data-augmentation technique (TACo). TACo divides the image into multiple small tiles of the same size. Then, vertical and horizontal tiles are corrupted by random noise. Finally, the modified tiles are joined back in the same order to create the new image. With TACo augmentations, the network can acquire valuable features and produce good results even on relatively small training sets.\n",
        "\n",
        "\n",
        "- To evaluate Easter2.0, the authors use IAM, publicly available datasets, and focus only on the line-level dataset. The contribution of several components of the model has been evaluated, such as the effect of TACo Augmentations, the effect of Residual Connections, and the effect of Squeeze-and-Excitation. The metric elected to compare results in the experiments is the case-sensitive Character Error Rate (CER). Results show that dealing with a small training dataset, Easter2.0 surpass SOTA works."
      ],
      "metadata": {
        "id": "lya2hVDoUgLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the Required Libraries"
      ],
      "metadata": {
        "id": "B5LswQk3ffkL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNCYRhbol9Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab45aab4-7883-42dd-fb43-42e2d14e20de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (2.8.2+zzzcolab20220929150707)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/DEL_Data/requirements.txt (line 2)) (4.6.0.66)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/DEL_Data/requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/DEL_Data/requirements.txt (line 4)) (0.5.3)\n",
            "Requirement already satisfied: taco-box in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/DEL_Data/requirements.txt (line 5)) (0.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/DEL_Data/requirements.txt (line 6)) (4.64.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (0.5.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (14.0.6)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (2.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (0.27.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (22.9.24)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.49.1)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (2.8.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r /content/drive/MyDrive/DEL_Data/requirements.txt (line 3)) (1.4.4)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! pip install -r /content/drive/MyDrive/DEL_Data/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Data \n",
        "- Create an account by registering\n",
        "- Activate the account using the link in email id"
      ],
      "metadata": {
        "id": "bvnM933Ap2MG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run following cells if you wish to download the data from the notebook"
      ],
      "metadata": {
        "id": "YiRevkxEDNtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USER = \"sanika.kulkarni@ucdconnect.ie\"\n",
        "PASSWORD = \"12345\""
      ],
      "metadata": {
        "id": "v5HdET-Uover"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  --save-cookies cookies.txt\\\n",
        "      --keep-session-cookies\\\n",
        "      --post-data 'email=$USER&password=$PASSWORD'\\\n",
        "      --delete-after\\\n",
        "        https://fki.tic.heia-fr.ch/login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykmaFLeEnOzX",
        "outputId": "7b02b004-c113-4890-c3b7-0e5f05a538a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-08 21:06:42--  https://fki.tic.heia-fr.ch/login\n",
            "Resolving fki.tic.heia-fr.ch (fki.tic.heia-fr.ch)... 160.98.46.146\n",
            "Connecting to fki.tic.heia-fr.ch (fki.tic.heia-fr.ch)|160.98.46.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4787 (4.7K) [text/html]\n",
            "Saving to: ‘login.tmp’\n",
            "\n",
            "login.tmp           100%[===================>]   4.67K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-08 21:06:43 (572 MB/s) - ‘login.tmp’ saved [4787/4787]\n",
            "\n",
            "Removing login.tmp.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies cookies.txt https://fki.tic.heia-fr.ch/DBs/iamDB/data/lines.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw1YPM6Sp8Jz",
        "outputId": "73462019-b9f4-4171-86b6-f21bf8f7388c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-08 21:06:43--  https://fki.tic.heia-fr.ch/DBs/iamDB/data/lines.tgz\n",
            "Resolving fki.tic.heia-fr.ch (fki.tic.heia-fr.ch)... 160.98.46.146\n",
            "Connecting to fki.tic.heia-fr.ch (fki.tic.heia-fr.ch)|160.98.46.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: http://fki.tic.heia-fr.ch/login [following]\n",
            "--2022-10-08 21:06:44--  http://fki.tic.heia-fr.ch/login\n",
            "Connecting to fki.tic.heia-fr.ch (fki.tic.heia-fr.ch)|160.98.46.146|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://fki.tic.heia-fr.ch/login [following]\n",
            "--2022-10-08 21:06:44--  https://fki.tic.heia-fr.ch/login\n",
            "Connecting to fki.tic.heia-fr.ch (fki.tic.heia-fr.ch)|160.98.46.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4720 (4.6K) [text/html]\n",
            "Saving to: ‘lines.tgz’\n",
            "\n",
            "lines.tgz           100%[===================>]   4.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-08 21:06:45 (421 MB/s) - ‘lines.tgz’ saved [4720/4720]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies cookies.txt https://fki.tic.heia-fr.ch/DBs/iamDB/data/ascii.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3__qSB7qdPU",
        "outputId": "effc00ef-6e52-42c7-d30d-bc7779f4f613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-08 21:06:45--  https://fki.tic.heia-fr.ch/DBs/iamDB/data/ascii.tgz\n",
            "Resolving fki.tic.heia-fr.ch (fki.tic.heia-fr.ch)... 160.98.46.146\n",
            "Connecting to fki.tic.heia-fr.ch (fki.tic.heia-fr.ch)|160.98.46.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: http://fki.tic.heia-fr.ch/login [following]\n",
            "--2022-10-08 21:06:46--  http://fki.tic.heia-fr.ch/login\n",
            "Connecting to fki.tic.heia-fr.ch (fki.tic.heia-fr.ch)|160.98.46.146|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://fki.tic.heia-fr.ch/login [following]\n",
            "--2022-10-08 21:06:46--  https://fki.tic.heia-fr.ch/login\n",
            "Connecting to fki.tic.heia-fr.ch (fki.tic.heia-fr.ch)|160.98.46.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4720 (4.6K) [text/html]\n",
            "Saving to: ‘ascii.tgz’\n",
            "\n",
            "ascii.tgz           100%[===================>]   4.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-08 21:06:47 (520 MB/s) - ‘ascii.tgz’ saved [4720/4720]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.openslr.org/resources/56/splits.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53QrfIxIqg6E",
        "outputId": "4b1627ed-60f4-46ae-f9b9-6eba942e78f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-08 21:06:47--  https://www.openslr.org/resources/56/splits.zip\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://us.openslr.org/resources/56/splits.zip [following]\n",
            "--2022-10-08 21:06:48--  http://us.openslr.org/resources/56/splits.zip\n",
            "Resolving us.openslr.org (us.openslr.org)... 46.101.158.64\n",
            "Connecting to us.openslr.org (us.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3304 (3.2K) [application/zip]\n",
            "Saving to: ‘splits.zip’\n",
            "\n",
            "splits.zip          100%[===================>]   3.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-10-08 21:06:49 (448 MB/s) - ‘splits.zip’ saved [3304/3304]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/data\n",
        "!mkdir /content/data/lines\n",
        "!mkdir /content/data/LWRT"
      ],
      "metadata": {
        "id": "wth_0KezqlUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/DEL_Data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTX6fAQD0PUd",
        "outputId": "fb8047d2-3f23-4a2e-8742-48f9e1e8088c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ascii.tar  lines.tar  requirements.txt\tsrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf /content/drive/MyDrive/DEL_Data/lines.tar -C /content/data/lines"
      ],
      "metadata": {
        "id": "MkFCWJiuNEWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xf /content/drive/MyDrive/DEL_Data/ascii.tar -C /content/"
      ],
      "metadata": {
        "id": "LLPeDjsUvsqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip splits.zip\n",
        "!mv splits/train.uttlist  /content/data/LWRT/\n",
        "!mv splits/test.uttlist  /content/data/LWRT/\n",
        "!mv splits/validation.uttlist  /content/data/LWRT/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puaZIIntMg7l",
        "outputId": "aa2d30e3-737d-40c5-8635-a093d5fe396c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  splits.zip\n",
            "  inflating: splits/test.uttlist     \n",
            "  inflating: splits/train.uttlist    \n",
            "  inflating: splits/validation.uttlist  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/lines.txt /content/data/lines.txt"
      ],
      "metadata": {
        "id": "62hu2XSB1e9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Easter_model.py \n",
        "Creating the model architecture"
      ],
      "metadata": {
        "id": "TW_SwPMiD0F_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes on config.py\n",
        "This file is used to define configuration settings. It should be edited before running the code. \n",
        "Settings for this code includes defining the foolowing:\n",
        "\n",
        "1.   Data paths and input parameters\n",
        "         DATA_PATH, INPUT_HEIGHT, INPUT_WIDTH, INPUT_SHAPE,TACO_AUGMENTAION_FRACTION\n",
        "\n",
        "2.  Long lines augmentation options\n",
        "      LONG_LINES (T/F), LONG_LINES_FRACTION\n",
        "\n",
        "2.   Model training parameters:\n",
        "          BATCH_SIZE, EPOCHS, VOCAB_SIZE = 80, DROPOUT (it is a flag), OUTPUT_SHAPE\n",
        "         \n",
        "3.  Learning parameters\n",
        "         Learning rate and batch normalization parameters\n",
        "4.  Option to initialize weights from pre-trained model by providing checkpoint path\n",
        "5.  Paths to store model checkpoints when training\n",
        "          CHECKPOINT_PATH, LOGS_DIR, BEST_MODEL_PATH "
      ],
      "metadata": {
        "id": "kOOqz07MvxW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import itertools, os, time\n",
        "import config\n",
        "config.DATA_PATH = '/content/data/'\n",
        "# Checkpoints parametes\n",
        "config.CHECKPOINT_PATH = '/content/weights/EASTER2--{epoch:02d}--{loss:.02f}.hdf5'\n",
        "config.LOGS_DIR = '/content/logs'\n",
        "config.BEST_MODEL_PATH = \"/content/weights/saved_checkpoint.hdf5\"\n",
        "import matplotlib.pyplot as plt\n",
        "from tacobox import Taco\n",
        "config.EPOCHS = 10\n",
        "\n",
        "import tensorflow\n",
        "import tensorflow.keras.backend as K"
      ],
      "metadata": {
        "id": "l4ibEV7VLEdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code for Loading the data and using Taco augmentation\n",
        "\n",
        "TACo divides the image into multiple small tiles of the same size. Then, vertical and horizontal tiles are corrupted by random noise. Finally, the modified tiles are joined back in the same order to create the new image. With TACo augmentations, the network can acquire valuable features and produce good results even on relatively small training sets."
      ],
      "metadata": {
        "id": "BdAr8pudcJ9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sample:\n",
        "    \"sample from the dataset\"\n",
        "    def __init__(self, gtText, filePath):\n",
        "        self.gtText = gtText\n",
        "        self.filePath = filePath\n",
        "        \n",
        "class data_loader:\n",
        "    def __init__(self, path, batch_size):\n",
        "        self.batchSize = batch_size\n",
        "        self.samples = []\n",
        "        self.currIdx = 0\n",
        "        self.charList = []\n",
        "        \n",
        "        # creating taco object for augmentation (checkout Easter2.0 paper)\n",
        "        self.mytaco = Taco(\n",
        "            cp_vertical=0.2,\n",
        "            cp_horizontal=0.25,\n",
        "            max_tw_vertical=100,\n",
        "            min_tw_vertical=10,\n",
        "            max_tw_horizontal=50,\n",
        "            min_tw_horizontal=10\n",
        "        )\n",
        "        \n",
        "        f = open(path + 'lines.txt')\n",
        "        chars = set()\n",
        "        for line in f:\n",
        "            if not line or line[0]=='#':\n",
        "                continue\n",
        "            lineSplit = line.strip().split(' ')\n",
        "            assert len(lineSplit) >= 9\n",
        "            fileNameSplit = lineSplit[0].split('-')\n",
        "            fileName = path + 'lines/' + fileNameSplit[0] + '/' +\\\n",
        "                       fileNameSplit[0] + '-' + fileNameSplit[1] + '/' + lineSplit[0] + '.png'\n",
        "            \n",
        "            gtText = lineSplit[8].strip(\" \").replace(\"|\", \" \")\n",
        "            \n",
        "            chars = chars.union(set(list(gtText)))\n",
        "            self.samples.append(Sample(gtText, fileName))\n",
        "        \n",
        "        train_folders = [x.strip(\"\\n\") for x in open(path+\"LWRT/train.uttlist\").readlines()]\n",
        "        validation_folders = [x.strip(\"\\n\") for x in open(path+\"LWRT/validation.uttlist\").readlines()]\n",
        "        test_folders = [x.strip(\"\\n\") for x in open(path+\"LWRT/test.uttlist\").readlines()]\n",
        "\n",
        "        self.trainSamples = []\n",
        "        self.validationSamples = []\n",
        "        self.testSamples = []\n",
        "\n",
        "        for i in range(0, len(self.samples)):\n",
        "            file = self.samples[i].filePath.split(\"/\")[-1][:-4].strip(\" \")\n",
        "            folder = \"-\".join(file.split(\"-\")[:-1])\n",
        "            if (folder in train_folders): \n",
        "                self.trainSamples.append(self.samples[i])\n",
        "            elif folder in validation_folders:\n",
        "                self.validationSamples.append(self.samples[i])\n",
        "            elif folder in test_folders:\n",
        "                self.testSamples.append(self.samples[i])\n",
        "        self.trainSet()\n",
        "        self.charList = sorted(list(chars))\n",
        "        \n",
        "        \n",
        "    def trainSet(self):\n",
        "        self.currIdx = 0\n",
        "        random.shuffle(self.trainSamples)\n",
        "        self.samples = self.trainSamples\n",
        "\n",
        "    def validationSet(self):\n",
        "        self.currIdx = 0\n",
        "        self.samples = self.validationSamples\n",
        "        \n",
        "    def testSet(self):\n",
        "        self.currIdx = 0\n",
        "        self.samples = self.testSamples\n",
        "        \n",
        "    def getIteratorInfo(self):\n",
        "        return (self.currIdx // self.batchSize + 1, len(self.samples) // self.batchSize)\n",
        "\n",
        "    def hasNext(self):\n",
        "        return self.currIdx + self.batchSize <= len(self.samples)\n",
        "    \n",
        "    def preprocess(self, img, augment=True):\n",
        "        if augment:\n",
        "            img = self.apply_taco_augmentations(img)\n",
        "            \n",
        "        # scaling image [0, 1]\n",
        "        img = img/255\n",
        "        img = img.swapaxes(-2,-1)[...,::-1]\n",
        "        target = np.ones((config.INPUT_WIDTH, config.INPUT_HEIGHT))\n",
        "        new_x = config.INPUT_WIDTH/img.shape[0]\n",
        "        new_y = config.INPUT_HEIGHT/img.shape[1]\n",
        "        min_xy = min(new_x, new_y)\n",
        "        new_x = int(img.shape[0]*min_xy)\n",
        "        new_y = int(img.shape[1]*min_xy)\n",
        "        img2 = cv2.resize(img, (new_y,new_x))\n",
        "        target[:new_x,:new_y] = img2\n",
        "        return 1 - (target)\n",
        "    \n",
        "    def apply_taco_augmentations(self, input_img):\n",
        "        random_value = random.random()\n",
        "        if random_value <= config.TACO_AUGMENTAION_FRACTION:\n",
        "            augmented_img = self.mytaco.apply_vertical_taco(\n",
        "                input_img, \n",
        "                corruption_type='random'\n",
        "            )\n",
        "        else:\n",
        "            augmented_img = input_img\n",
        "        return augmented_img\n",
        "\n",
        "    def getNext(self, what='train'):\n",
        "        while True:\n",
        "            if ((self.currIdx + self.batchSize) <= len(self.samples)):\n",
        "                \n",
        "                itr = self.getIteratorInfo()\n",
        "                batchRange = range(self.currIdx, self.currIdx + self.batchSize)\n",
        "                if config.LONG_LINES:\n",
        "                    random_batch_range = random.choices(range(0, len(self.samples)), k=self.batchSize)\n",
        "                    \n",
        "                gtTexts = np.ones([self.batchSize, config.OUTPUT_SHAPE])\n",
        "                input_length = np.ones((self.batchSize,1))*config.OUTPUT_SHAPE\n",
        "                label_length = np.zeros((self.batchSize,1))\n",
        "                imgs = np.ones([self.batchSize, config.INPUT_WIDTH, config.INPUT_HEIGHT])\n",
        "                j = 0;\n",
        "                for ix, i in enumerate(batchRange):\n",
        "                    img = cv2.imread(self.samples[i].filePath, cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is None:\n",
        "                        img = np.zeros([config.INPUT_WIDTH, config.INPUT_HEIGHT])\n",
        "                    text = self.samples[i].gtText\n",
        "                    \n",
        "                    if config.LONG_LINES:\n",
        "                        if random.random() <= config.LONG_LINES_FRACTION:\n",
        "                            index = random_batch_range[ix]\n",
        "                            img2 = cv2.imread(self.samples[index].filePath, cv2.IMREAD_GRAYSCALE)\n",
        "                            if img2 is None:\n",
        "                                img2 = np.zeros([config.INPUT_WIDTH, config.INPUT_HEIGHT])\n",
        "                            text2 = self.samples[index].gtText\n",
        "                            \n",
        "                            avg_w = (img.shape[1] + img2.shape[1])//2\n",
        "                            avg_h = (img.shape[0] + img2.shape[0])//2\n",
        "                            \n",
        "                            resized1 = cv2.resize(img, (avg_w, avg_h))\n",
        "                            resized2 = cv2.resize(img2, (avg_w, avg_h))\n",
        "                            space_width = random.randint(config.INPUT_HEIGHT//4, 2*config.INPUT_HEIGHT)\n",
        "                            space = np.ones((avg_h, space_width))*255\n",
        "                            \n",
        "                            img = np.hstack([resized1, space, resized2])\n",
        "                            text = text + \" \" + text2\n",
        "                            \n",
        "                    if len(self.samples) < 3000:# FOR VALIDATION AND TEST SETS\n",
        "                        eraser=-1\n",
        "                    img = self.preprocess(img)                    \n",
        "                    imgs[j] = img\n",
        "                    \n",
        "                    val = list(map(lambda x: self.charList.index(x), text))\n",
        "                    while len(val) < config.OUTPUT_SHAPE:\n",
        "                        val.append(len(self.charList))\n",
        "                        \n",
        "                    gtTexts[j] = (val)\n",
        "                    label_length[j] = len(text)\n",
        "                    input_length[j] = config.OUTPUT_SHAPE\n",
        "                    j = j + 1\n",
        "                    if False:\n",
        "                        plt.figure( figsize = (20, 20))\n",
        "                        plt.imshow(img)\n",
        "                        plt.show()\n",
        "                        \n",
        "                self.currIdx += self.batchSize\n",
        "                inputs = {\n",
        "                        'the_input': imgs,\n",
        "                        'the_labels': gtTexts,\n",
        "                        'input_length': input_length,\n",
        "                        'label_length': label_length,\n",
        "                }\n",
        "                outputs = {'ctc': np.zeros([self.batchSize])}\n",
        "                yield (inputs,outputs)\n",
        "            else:\n",
        "                self.currIdx = 0\n",
        "                \n",
        "    def getValidationImage(self):\n",
        "        batchRange = range(0, len(self.samples))\n",
        "        imgs = []\n",
        "        texts = []\n",
        "        reals = []\n",
        "        for i in batchRange:\n",
        "            img1 = cv2.imread(self.samples[i].filePath, cv2.IMREAD_GRAYSCALE)\n",
        "            real = cv2.imread(self.samples[i].filePath)\n",
        "            if img1 is None:\n",
        "                img1 = np.zeros([config.INPUT_WIDTH, config.INPUT_HEIGHT])\n",
        "            img = self.preprocess(img1, augment=False)\n",
        "            img = np.expand_dims(img,  0)\n",
        "            text = self.samples[i].gtText\n",
        "            imgs.append(img)\n",
        "            texts.append(text)\n",
        "            reals.append(real)\n",
        "        self.currIdx += self.batchSize\n",
        "        return imgs,texts,reals\n",
        "    \n",
        "    def getTestImage(self):\n",
        "        batchRange = range(0, len(self.samples))\n",
        "        imgs = []\n",
        "        texts = []\n",
        "        reals = []\n",
        "        for i in batchRange:\n",
        "            img1 = cv2.imread(self.samples[i].filePath, cv2.IMREAD_GRAYSCALE)\n",
        "            real = cv2.imread(self.samples[i].filePath)\n",
        "            if img1 is None:\n",
        "                img1 = np.zeros([config.INPUT_WIDTH, config.INPUT_HEIGHT])\n",
        "            img = self.preprocess(img1, augment=False)\n",
        "            img = np.expand_dims(img,  0)\n",
        "            text = self.samples[i].gtText\n",
        "            imgs.append(img)\n",
        "            texts.append(text)\n",
        "            reals.append(real)\n",
        "        self.currIdx += self.batchSize\n",
        "        return imgs,texts,reals"
      ],
      "metadata": {
        "id": "QqCYSCFSL3VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code for building easter model\n",
        "1. Define function for calculating CTC loss\n",
        "\n",
        "4. Easter Unit \n",
        "### Notes on easter_model.py\n",
        "https://sid2697.github.io/Blog_Sid/algorithm/2019/10/19/CTC-Loss.html\n",
        "\n",
        "**CTC Loss:** This is used to calculate loss when it comes to HTR tasks.\n",
        "1. **Encoding**\n",
        " There can be letters of different width and thus characters can take up more than one time-step in the image. This can lead to wrong predictions. To solve this issue, CTC merges all the repeating characters into a single character. \n",
        "\n",
        "![](https://sid2697.github.io/Blog_Sid/assets/images/CTC_2.png)\n",
        "\n",
        "\n",
        "\n",
        "For example, if the word in the image is ‘hey’ where ‘h’ takes three time-steps, ‘e’ and ‘y’ take one time-step each. Then the output from the network using CTC will be ‘hhhey’, which as per our encoding scheme, gets collapsed to ‘hey’.\n",
        "\n",
        "What about the words where there are repeating characters? For handling those cases, CTC introduces a pseudo-character called blank denoted as “-“ in the following examples. While encoding the text, if a character repeats, then a blank is placed between the characters in the output text. Let’s consider the word ‘meet’, possible encodings for it will be, ‘mm-ee-ee-t’, ‘mmm-e-e-ttt’, wrong encoding will be ‘mm-eee-tt’, as it’ll result in ‘met’ when decoded. The CRNN is trained to output the encoded text.\n",
        "\n",
        "\n",
        "\n",
        "2. **Loss calculation and Decoding:**\n",
        "\n",
        "![](https://sid2697.github.io/Blog_Sid/assets/images/CTC_3.png)\n",
        "\n",
        "Corresponding character scores are multiplied together to get the score for one path. In Fig above, the score for the path “a–” is 0.4x0.7x0.6 = 0.168, and for the path “aaa” is 0.4x0.3x0.4 = 0.048. For getting the score corresponding to given ground truth, scores of all the paths to the corresponding text are summed up. The loss is the negative logarithm of probability, it can be calculated easily. This loss can be back-propagated and the network can be trained.\n",
        "\n",
        "Decoding consists of the following two steps:\n",
        "\n",
        "- Calculates the best path by considering the character with max probability at every time-step.\n",
        "- This step involves removing blanks and duplicate characters, which results in the actual text.\n",
        "\n",
        "For example, let us consider the matrix in Fig. If we consider the first time-step t0, then the character with maximum probability is ‘b’. For t1 and t2 character with maximum probability is ‘-‘ and ‘-‘ respectively. So, the output text according to the best path algorithm for matrix in Fig.3 after decoding is ‘b’.\n",
        "\n",
        "\n",
        "**Advantages:**\n",
        "- CTC is formulated in such a way, that it only requires the text that occurs in the image. We can ignore both the width and position of the characters in an image.\n",
        "- There is no need for post-processing the output of the CTC operation! Using decoding techniques, we can directly get the result of the network.\n"
      ],
      "metadata": {
        "id": "5Gz6t6UncQ21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ctc_loss(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return K.ctc_batch_cost(\n",
        "        labels, \n",
        "        y_pred, \n",
        "        input_length, \n",
        "        label_length\n",
        "    )\n",
        "\n",
        "def ctc_custom(args):\n",
        "    \"\"\"\n",
        "    custom CTC loss\n",
        "    \"\"\"\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    ctc_loss = K.ctc_batch_cost(\n",
        "        labels, \n",
        "        y_pred, \n",
        "        input_length, \n",
        "        label_length\n",
        "    )\n",
        "    p = tensorflow.exp(-ctc_loss)\n",
        "    gamma = 0.5\n",
        "    alpha=0.25 \n",
        "    return alpha*(K.pow((1-p),gamma))*ctc_loss"
      ],
      "metadata": {
        "id": "vPUK2cScXfyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Batch normalization function"
      ],
      "metadata": {
        "id": "GwlnkWBicb5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_norm(inputs):\n",
        "    return tensorflow.keras.layers.BatchNormalization(\n",
        "        momentum= config.BATCH_NORM_DECAY, \n",
        "        epsilon = config.BATCH_NORM_EPSILON\n",
        "    )(inputs)\n"
      ],
      "metadata": {
        "id": "-qAgBj2D09E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Squeeze and Excitation function for adding global context\n",
        "\n",
        "CNNs use their convolutional filters to extract hierarchal information from images. Lower layers find trivial pieces of context like edges or high frequencies, while upper layers can detect faces, text or other complex geometrical shapes. They extract whatever is necessary to solve a task efficiently.\n",
        "\n",
        "All of this works by fusing the spatial and channel information of an image. The different filters will first find spatial features in each input channel before adding the information across all available output channels.\n",
        "\n",
        "Originally, CNNs gave same weights to all channels of the image. SE changes that by:\n",
        "\n",
        "1. Getting a global understanding of each channel by squeezing the feature maps to a single numeric value. This results in a vector of size n, where n is equal to the number of convolutional channels. \n",
        "2. Afterwards, it is fed through a two-layer neural network having RELU and Sigmoid functions to obtain weights. These are then used on the original feature map to scale each channel based on its importance.\n",
        "\n",
        "The local features are squeezed into a single global context vector of weights. The SE module broadcasts this context to each local feature vector thanks to an element-wise multiplication of context weights with features."
      ],
      "metadata": {
        "id": "siD2agzIcmHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_global_context(data, filters):\n",
        "    \"\"\"\n",
        "    1D Squeeze and Excitation Layer. \n",
        "    \"\"\"\n",
        "    pool = tensorflow.keras.layers.GlobalAveragePooling1D()(data)\n",
        "    \n",
        "    pool = tensorflow.keras.layers.Dense(\n",
        "        filters//8, \n",
        "        activation='relu'\n",
        "    )(pool)\n",
        "    \n",
        "    pool = tensorflow.keras.layers.Dense(\n",
        "        filters, \n",
        "        activation='sigmoid'\n",
        "    )(pool) \n",
        "    \n",
        "    final = tensorflow.keras.layers.Multiply()([data, pool])\n",
        "    return final"
      ],
      "metadata": {
        "id": "hMJtwpdVck4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Easter block\n",
        "\n",
        "\n",
        "\n",
        "   1. Components of EASTER block (Repeated): \n",
        "   \n",
        "   Each block contains multiple repeating sub-blocks consisting of layers for 1-D Conv, Batch Normalisation, ReLU and Dropout. Different blocks utilize different number of convolutional filters and other hyperparameters. \n",
        "   \n",
        "   2. Residual connections and global context:\n",
        "\n",
        "   Residual connections are used to connect the output of older convolution layer with the input of current layer by skipping few layers in between.\n",
        "   \n",
        "   The third block conatins SE layer before ReLU and dropout to add global context.\n",
        "   The current and old inputs are added toghether and this is then added to the output of SE layer before passing through ReLU and Dropout steps.\n",
        "\n",
        "![](http://www.marktechpost.com/wp-content/uploads/2022/08/Screen-Shot-2022-08-03-at-8.50.55-AM.png)"
      ],
      "metadata": {
        "id": "hu7gdSwecgfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def easter_unit(old, data, filters, kernel, stride, dropouts):\n",
        "    \"\"\"\n",
        "    Easter unit with dense residual connections\n",
        "    \"\"\"\n",
        "    old = tensorflow.keras.layers.Conv1D(\n",
        "        filters = filters, \n",
        "        kernel_size = (1), \n",
        "        strides = (1),\n",
        "        padding = \"same\"\n",
        "    )(old)\n",
        "    old = batch_norm(old)\n",
        "    \n",
        "    this = tensorflow.keras.layers.Conv1D(\n",
        "        filters = filters, \n",
        "        kernel_size = (1), \n",
        "        strides = (1),\n",
        "        padding = \"same\"\n",
        "    )(data)\n",
        "    this = batch_norm(this)\n",
        "    \n",
        "    old = tensorflow.keras.layers.Add()([old, this])\n",
        "    \n",
        "    #First Block\n",
        "    data = tensorflow.keras.layers.Conv1D(\n",
        "        filters = filters, \n",
        "        kernel_size = (kernel), \n",
        "        strides = (stride),\n",
        "        padding = \"same\"\n",
        "    )(data)\n",
        "    \n",
        "    data = batch_norm(data)\n",
        "    data = tensorflow.keras.layers.Activation('relu')(data)\n",
        "    data = tensorflow.keras.layers.Dropout(dropouts)(data)\n",
        "    \n",
        "    #Second Block\n",
        "    data = tensorflow.keras.layers.Conv1D(\n",
        "        filters = filters, \n",
        "        kernel_size = (kernel), \n",
        "        strides = (stride),\n",
        "        padding = \"same\"\n",
        "    )(data)\n",
        "    \n",
        "    data = batch_norm(data)\n",
        "    data = tensorflow.keras.layers.Activation('relu')(data)\n",
        "    data = tensorflow.keras.layers.Dropout(dropouts)(data)\n",
        "    \n",
        "    #Third Block\n",
        "    data = tensorflow.keras.layers.Conv1D(\n",
        "        filters = filters, \n",
        "        kernel_size = (kernel), \n",
        "        strides = (stride),\n",
        "        padding = \"same\"\n",
        "    )(data)\n",
        "    \n",
        "    data = batch_norm(data)\n",
        "    \n",
        "    #squeeze and excitation\n",
        "    data = add_global_context(data, filters)\n",
        "    \n",
        "    final = tensorflow.keras.layers.Add()([old,data])\n",
        "    \n",
        "    data = tensorflow.keras.layers.Activation('relu')(final)\n",
        "    data = tensorflow.keras.layers.Dropout(dropouts)(data)\n",
        "       \n",
        "    return data, old"
      ],
      "metadata": {
        "id": "RpCpEUX01AyP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Easter 2 code:\n",
        "\n",
        "  1. First an input layer is created using input shape\n",
        "  2. Two layers of conv1d are created (Block type A) with different filters\n",
        "  3. The output of second layer is copied to 'old' which is then passed to the above `easter()` function along with the output itself and few more parameter values\n",
        "  4. Three such blocks are created. \n",
        "  5. Again 2 Block type A are created with different filter sizes \n",
        "  6. Then a final output layer is created with softmax activation function\n",
        "  7. Adam optimizer is used to optimize the ctc loss\n",
        "  8. Model is complied"
      ],
      "metadata": {
        "id": "iao0k0QfuExm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Easter2():\n",
        "    input_data = tensorflow.keras.layers.Input(\n",
        "        name='the_input', \n",
        "        shape = config.INPUT_SHAPE\n",
        "    )\n",
        "    \n",
        "    data = tensorflow.keras.layers.Conv1D(\n",
        "        filters = 128, \n",
        "        kernel_size = (3), \n",
        "        strides = (2), \n",
        "        padding = \"same\"\n",
        "    )(input_data)\n",
        "    \n",
        "    data = batch_norm(data)\n",
        "    data = tensorflow.keras.layers.Activation('relu')(data)\n",
        "    data = tensorflow.keras.layers.Dropout(0.2)(data)\n",
        "\n",
        "    data = tensorflow.keras.layers.Conv1D(\n",
        "        filters = 128, \n",
        "        kernel_size = (3), \n",
        "        strides = (2), \n",
        "        padding = \"same\"\n",
        "    )(data)\n",
        "    \n",
        "    data = batch_norm(data)\n",
        "    data = tensorflow.keras.layers.Activation('relu')(data)\n",
        "    data = tensorflow.keras.layers.Dropout(0.2)(data)\n",
        "\n",
        "    old = data\n",
        "\n",
        "    # 3 * 3 Easter Blocks (with dense residuals)\n",
        "    data, old = easter_unit(old, data, 256, 5, 1, 0.2)\n",
        "    data, old = easter_unit(old, data, 256, 7, 1, 0.2 )\n",
        "    data, old = easter_unit(old, data, 256, 9, 1, 0.3 )\n",
        "\n",
        "    data = tensorflow.keras.layers.Conv1D(\n",
        "        filters = 512, \n",
        "        kernel_size = (11), \n",
        "        strides = (1), \n",
        "        padding = \"same\", \n",
        "        dilation_rate = 2\n",
        "    )(data)\n",
        "    \n",
        "    data = batch_norm(data)\n",
        "    data = tensorflow.keras.layers.Activation('relu')(data)\n",
        "    data = tensorflow.keras.layers.Dropout(0.4)(data)\n",
        "\n",
        "    data = tensorflow.keras.layers.Conv1D(\n",
        "        filters = 512, \n",
        "        kernel_size = (1), \n",
        "        strides = (1), \n",
        "        padding = \"same\"\n",
        "    )(data)\n",
        "    \n",
        "    data = batch_norm(data)\n",
        "    data = tensorflow.keras.layers.Activation('relu')(data)\n",
        "    data = tensorflow.keras.layers.Dropout(0.4)(data)\n",
        "\n",
        "    data = tensorflow.keras.layers.Conv1D(\n",
        "        filters = config.VOCAB_SIZE, \n",
        "        kernel_size = (1), \n",
        "        strides = (1), \n",
        "        padding = \"same\"\n",
        "    )(data)\n",
        "    \n",
        "    y_pred = tensorflow.keras.layers.Activation('softmax',name=\"Final\")(data)\n",
        "\n",
        "    # print model summary\n",
        "    tensorflow.keras.models.Model(inputs = input_data, outputs = y_pred).summary()\n",
        " \n",
        "    # Defining other training parameters\n",
        "    Optimizer = tensorflow.keras.optimizers.Adam(lr = config.LEARNING_RATE)\n",
        "    \n",
        "    labels = tensorflow.keras.layers.Input(\n",
        "        name = 'the_labels', \n",
        "        shape=[config.OUTPUT_SHAPE], \n",
        "        dtype='float32'\n",
        "    )\n",
        "    input_length = tensorflow.keras.layers.Input(\n",
        "        name='input_length', \n",
        "        shape=[1],\n",
        "        dtype='int64'\n",
        "    )\n",
        "    label_length = tensorflow.keras.layers.Input(\n",
        "        name='label_length',\n",
        "        shape=[1],\n",
        "        dtype='int64'\n",
        "    )\n",
        "    \n",
        "    output = tensorflow.keras.layers.Lambda(\n",
        "        ctc_custom, output_shape=(1,),name='ctc'\n",
        "    )([y_pred, labels, input_length, label_length])\n",
        "\n",
        "    # compiling model\n",
        "    model = tensorflow.keras.models.Model(\n",
        "        inputs = [input_data, labels, input_length, label_length], outputs= output\n",
        "    )\n",
        "    \n",
        "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = Optimizer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "EBN11-0_1Hiy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    #Creating Easter2 object\n",
        "    model = Easter2()\n",
        "    \n",
        "    '''\n",
        "    # Loading checkpoint for transfer/resuming learning\n",
        "    if config.LOAD:\n",
        "        print (\"Intializing from checkpoint : \", config.LOAD_CHECKPOINT_PATH)\n",
        "        model.load_weights(config.LOAD_CHECKPOINT_PATH)\n",
        "        print (\"Init weights loaded successfully....\")'''\n",
        "        \n",
        "    # Loading Metadata, about training, validation and Test sets\n",
        "    print (\"loading metdata...\")\n",
        "    training_data = data_loader(config.DATA_PATH, config.BATCH_SIZE)\n",
        "    validation_data = data_loader(config.DATA_PATH, config.BATCH_SIZE)\n",
        "    test_data = data_loader(config.DATA_PATH, config.BATCH_SIZE)\n",
        "\n",
        "    training_data.trainSet()\n",
        "    validation_data.validationSet()\n",
        "    test_data.testSet()\n",
        "\n",
        "    print(\"Training Samples : \", len(training_data.samples))\n",
        "    print(\"Validation Samples : \", len(validation_data.samples))\n",
        "    print(\"Test Samples : \", len(test_data.samples))\n",
        "    print(\"CharList Size : \", len(training_data.charList))\n",
        "    \n",
        "    # callback arguments\n",
        "    CHECKPOINT = tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "        filepath = config.CHECKPOINT_PATH,\n",
        "        monitor='loss', \n",
        "        verbose=1, \n",
        "        mode='min', \n",
        "        period = 2\n",
        "    )\n",
        "    \n",
        "    TENSOR_BOARD = tensorflow.keras.callbacks.TensorBoard(\n",
        "        log_dir=config.LOGS_DIR, \n",
        "        histogram_freq=0, \n",
        "        write_graph=True,\n",
        "        write_images=False, \n",
        "        embeddings_freq=0\n",
        "    )\n",
        "    \n",
        "    # steps per epoch calculation based on number of samples and batch size\n",
        "    STEPS_PER_EPOCH = len(training_data.samples)//config.BATCH_SIZE\n",
        "    VALIDATION_STEPS = len(validation_data.samples)//config.BATCH_SIZE\n",
        "\n",
        "    # Start training with given parameters\n",
        "    print (\"Training Model...\")\n",
        "    model.fit_generator(\n",
        "        generator = training_data.getNext(), \n",
        "        steps_per_epoch = STEPS_PER_EPOCH,\n",
        "        epochs = config.EPOCHS,\n",
        "        callbacks=[CHECKPOINT, TENSOR_BOARD],\n",
        "        validation_data = validation_data.getNext(), \n",
        "        validation_steps = VALIDATION_STEPS\n",
        "    )"
      ],
      "metadata": {
        "id": "yo-ma9af1R9r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCK3fRMn1beC",
        "outputId": "d9dbbf09-c295-44f5-b9f5-c4bd04bd4bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " the_input (InputLayer)         [(None, 2000, 80)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 1000, 128)    30848       ['the_input[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 1000, 128)   512         ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 1000, 128)    0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1000, 128)    0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 500, 128)     49280       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 500, 128)    512         ['conv1d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 500, 128)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 500, 128)     0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 500, 256)     164096      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 500, 256)    1024        ['conv1d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 500, 256)     0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 500, 256)     0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 500, 256)     327936      ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 500, 256)    1024        ['conv1d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 500, 256)     0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 500, 256)     0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 500, 256)     327936      ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 500, 256)    1024        ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 256)         0           ['batch_normalization_6[0][0]']  \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 500, 256)     33024       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 500, 256)     33024       ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           8224        ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 500, 256)    1024        ['conv1d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 500, 256)    1024        ['conv1d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          8448        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 500, 256)     0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 500, 256)     0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 500, 256)     0           ['add[0][0]',                    \n",
            "                                                                  'multiply[0][0]']               \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 500, 256)     0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 500, 256)     0           ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 500, 256)     459008      ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 500, 256)    1024        ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 500, 256)     0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 500, 256)     0           ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 500, 256)     459008      ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 500, 256)    1024        ['conv1d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 500, 256)     0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 500, 256)     0           ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 500, 256)     459008      ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 500, 256)    1024        ['conv1d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling1d_1 (Gl  (None, 256)         0           ['batch_normalization_11[0][0]'] \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 500, 256)     65792       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 500, 256)     65792       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 32)           8224        ['global_average_pooling1d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 500, 256)    1024        ['conv1d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 500, 256)    1024        ['conv1d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 256)          8448        ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 500, 256)     0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)          (None, 500, 256)     0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 500, 256)     0           ['add_2[0][0]',                  \n",
            "                                                                  'multiply_1[0][0]']             \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 500, 256)     0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 500, 256)     0           ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 500, 256)     590080      ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 500, 256)    1024        ['conv1d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 500, 256)     0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 500, 256)     0           ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 500, 256)     590080      ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 500, 256)    1024        ['conv1d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 500, 256)     0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 500, 256)     0           ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)             (None, 500, 256)     590080      ['dropout_9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 500, 256)    1024        ['conv1d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling1d_2 (Gl  (None, 256)         0           ['batch_normalization_16[0][0]'] \n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 500, 256)     65792       ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 500, 256)     65792       ['dropout_7[0][0]']              \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 32)           8224        ['global_average_pooling1d_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 500, 256)    1024        ['conv1d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 500, 256)    1024        ['conv1d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 256)          8448        ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 500, 256)     0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)          (None, 500, 256)     0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 500, 256)     0           ['add_4[0][0]',                  \n",
            "                                                                  'multiply_2[0][0]']             \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 500, 256)     0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 500, 256)     0           ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)             (None, 500, 512)     1442304     ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 500, 512)    2048        ['conv1d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 500, 512)     0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 500, 512)     0           ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_18 (Conv1D)             (None, 500, 512)     262656      ['dropout_11[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 500, 512)    2048        ['conv1d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 500, 512)     0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 500, 512)     0           ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_19 (Conv1D)             (None, 500, 80)      41040       ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " Final (Activation)             (None, 500, 80)      0           ['conv1d_19[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,193,072\n",
            "Trainable params: 6,182,832\n",
            "Non-trainable params: 10,240\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading metdata...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Samples :  6482\n",
            "Validation Samples :  976\n",
            "Test Samples :  2915\n",
            "CharList Size :  79\n",
            "Training Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "202/202 [==============================] - 147s 647ms/step - loss: 51.8876 - val_loss: 175.0662\n",
            "Epoch 2/10\n",
            "202/202 [==============================] - ETA: 0s - loss: 43.7700\n",
            "Epoch 2: saving model to /content/weights/EASTER2--02--43.77.hdf5\n",
            "202/202 [==============================] - 135s 668ms/step - loss: 43.7700 - val_loss: 86.1898\n",
            "Epoch 3/10\n",
            "202/202 [==============================] - 129s 637ms/step - loss: 40.6019 - val_loss: 59.6506\n",
            "Epoch 4/10\n",
            "202/202 [==============================] - ETA: 0s - loss: 39.5380\n",
            "Epoch 4: saving model to /content/weights/EASTER2--04--39.54.hdf5\n",
            "202/202 [==============================] - 127s 628ms/step - loss: 39.5380 - val_loss: 45.9494\n",
            "Epoch 5/10\n",
            "202/202 [==============================] - 116s 573ms/step - loss: 36.5264 - val_loss: 47.2678\n",
            "Epoch 6/10\n",
            "202/202 [==============================] - ETA: 0s - loss: 37.1536\n",
            "Epoch 6: saving model to /content/weights/EASTER2--06--37.15.hdf5\n",
            "202/202 [==============================] - 126s 625ms/step - loss: 37.1536 - val_loss: 52.3362\n",
            "Epoch 7/10\n",
            "202/202 [==============================] - 126s 623ms/step - loss: 35.1930 - val_loss: 34.5065\n",
            "Epoch 8/10\n",
            "202/202 [==============================] - ETA: 0s - loss: 33.7774\n",
            "Epoch 8: saving model to /content/weights/EASTER2--08--33.78.hdf5\n",
            "202/202 [==============================] - 117s 577ms/step - loss: 33.7774 - val_loss: 33.6831\n",
            "Epoch 9/10\n",
            "202/202 [==============================] - 126s 622ms/step - loss: 32.9678 - val_loss: 34.3396\n",
            "Epoch 10/10\n",
            "202/202 [==============================] - ETA: 0s - loss: 31.4942\n",
            "Epoch 10: saving model to /content/weights/EASTER2--10--31.49.hdf5\n",
            "202/202 [==============================] - 126s 622ms/step - loss: 31.4942 - val_loss: 31.7495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code for predicting using the trained model"
      ],
      "metadata": {
        "id": "rCfwsN_jdL-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "from editdistance import eval as edit_distance\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "xD1uWjhMl_OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Code to load the model\n",
        "- If checkpoint path is empty then copy the path of best model using the config file\n",
        "- Load model\n",
        "- If unable to load then print the error message."
      ],
      "metadata": {
        "id": "OlV3Fh_XeGCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_easter_model(checkpoint_path):\n",
        "    if checkpoint_path == \"Empty\":\n",
        "        checkpoint_path = config.BEST_MODEL_PATH\n",
        "    try:\n",
        "        checkpoint = tensorflow.keras.models.load_model(\n",
        "            checkpoint_path,\n",
        "            custom_objects={'<lambda>': lambda x, y: y,\n",
        "            'tf':tf}\n",
        "        )\n",
        "        \n",
        "        EASTER = tensorflow.keras.models.Model(\n",
        "            checkpoint.get_layer('the_input').input,\n",
        "            checkpoint.get_layer('Final').output\n",
        "        )\n",
        "    except:\n",
        "        print (\"Unable to Load Checkpoint.\")\n",
        "        return None\n",
        "    return EASTER"
      ],
      "metadata": {
        "id": "CrAt8Y8tdr1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(output,letters):\n",
        "    ret = []\n",
        "    for j in range(output.shape[0]):\n",
        "        out_best = list(np.argmax(output[j,:], 1))\n",
        "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
        "        outstr = ''\n",
        "        for c in out_best:\n",
        "            if c < len(letters):\n",
        "                outstr += letters[c]\n",
        "        ret.append(outstr)\n",
        "    return ret"
      ],
      "metadata": {
        "id": "r3pMteXveDiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_on_iam(show = True, partition='test', uncased=False, checkpoint=\"Empty\"):\n",
        "    \n",
        "    print (\"loading metdata...\")\n",
        "    training_data = data_loader(config.DATA_PATH, config.BATCH_SIZE)\n",
        "    validation_data = data_loader(config.DATA_PATH, config.BATCH_SIZE)\n",
        "    test_data = data_loader(config.DATA_PATH, config.BATCH_SIZE)\n",
        "\n",
        "    training_data.trainSet()\n",
        "    validation_data.validationSet()\n",
        "    test_data.testSet()\n",
        "    charlist = training_data.charList\n",
        "    print (\"loading checkpoint...\")\n",
        "    print (\"calculating results...\")\n",
        "    \n",
        "    model = load_easter_model(checkpoint)\n",
        "    char_error = 0\n",
        "    total_chars = 0\n",
        "    \n",
        "    batches = 1\n",
        "    while batches > 0:\n",
        "        batches = batches - 1\n",
        "        if partition == 'validation':\n",
        "            print (\"Using Validation Partition\")\n",
        "            imgs, truths, _ = validation_data.getValidationImage()\n",
        "        else:\n",
        "            print (\"Using Test Partition\")\n",
        "            imgs,truths,_ = test_data.getTestImage()\n",
        "\n",
        "        print (\"Number of Samples : \",len(imgs))\n",
        "        for i in tqdm(range(0,len(imgs))):\n",
        "            img = imgs[i]\n",
        "            truth = truths[i].strip(\" \").replace(\"  \",\" \")\n",
        "            output = model.predict(img)\n",
        "            prediction = decoder(output, charlist)\n",
        "            output = (prediction[0].strip(\" \").replace(\"  \", \" \"))\n",
        "            if uncased:\n",
        "                char_error += edit_distance(output.lower(),truth.lower())\n",
        "            else:\n",
        "                char_error += edit_distance(output,truth)\n",
        "                \n",
        "            total_chars += len(truth)\n",
        "            if show:\n",
        "                print (\"Ground Truth :\", truth)\n",
        "                print(\"Prediction [\",edit_distance(output,truth),\"]  : \",output)\n",
        "                print (\"*\"*50)\n",
        "    print (\"Character error rate is : \",(char_error/total_chars)*100)"
      ],
      "metadata": {
        "id": "S6AHr6IVeAd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yRLaHcsWdLLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/weights/EASTER2--10--31.49.hdf5\""
      ],
      "metadata": {
        "id": "cFqP6LZmj8t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_on_iam(show=False, partition=\"validation\", checkpoint=checkpoint_path, uncased=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuYMl2QOilu5",
        "outputId": "61877021-00c2-4e45-b30c-189bd8ea2e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading metdata...\n",
            "loading checkpoint...\n",
            "calculating results...\n",
            "Using Validation Partition\n",
            "Number of Samples :  976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 976/976 [00:50<00:00, 19.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character error rate is :  63.972951736946115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_on_iam(show=False, partition=\"test\", checkpoint=checkpoint_path, uncased=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e09nBd-Zi9gn",
        "outputId": "ea2335a8-23a9-405f-930b-d3deeb48d97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading metdata...\n",
            "loading checkpoint...\n",
            "calculating results...\n",
            "Using Test Partition\n",
            "Number of Samples :  2915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2915/2915 [02:47<00:00, 17.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character error rate is :  67.88227971336003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X9xQwPlenO8B"
      }
    }
  ]
}